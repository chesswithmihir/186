# Introduction to DBMS Internals

We will be looking at DBMS Architecture and Data Storage today.

So let's do a little bit of recap:

Here is a course overview:

- Unit 1: Relational model and SQL
- Unit 2: Storage and indexing
- Unit 3: Query execution
- Unit 4: Query Optimization
- Unit 5: Conceptual design
- Unit 6: Transactions
- Unit 7: Recovery
- Unit 8: NoSQL

We are currentlyon Unit 2 and we are done with Unit 1 to get your hands dirty with SQL. Now we are doing a deep dive into how to actually build a DBMS.

The first topic is to go all the way down in the software stack to talk about how data is organized in disks. For those of you who enjoyed 61C, you will enjoy the class a lot. If not, you have Professor Cheung's condolences. 

### DBMS Architecture

We typically talk about cients and this is for anyone who wants to write queries. 

At the very bottom of the stack is actually the File System. This is where all the data is stored or where the data actually is. Fundamentally, we want to store the data in the file system.

How is the query then executed?

The query first gets parsed, then checked and then verified by the SQL in the sense that its referring to the right tables and that the tables actually exist. We actually refer to columns that are there. This is the verification. Then there is some optimization to perform the actual query.

Then from SQL queries, we make a SQL query execution plan which has the goal of how to retrieve the data from the files. No longer a String of SQL. Now it's a Tree.

| Node | parent |
| -- | -- |
|Heap Scan Reserves | Indexed Join | 
| Indexed Scan Sailors | Indexed Join | 
|Indexed Join | GroupBy (Age) |

Executing the plan goes into details about which files we go into. Do we have indices? There is an index management component that keeps track of which files to receive. Even another layer is buffer management, if we have access to the same data over and over again, we might wanna keep this in memory. In 61C, we learned about cache. We must control cache, and this is where buffer management is. I think this is like the TLB.

Finally, we have the disk management component, which opens the file from the disk and then retrieves the data.

So this is the rough division of labor.

If you don't understand every single detail, thats what the next 2 months are for lol.

Architecture of a DBMS
- Organized in layers

Useful to take in future classes. OS has different abstractions but same principles of levels and abstractions. Very good for systems classes.

Example of good systems design. If you open a commercial DB implementation or any open source DB, they all have this division of labor to show that all have the same abstractions. A lot of the startups do the same thing. Cookbook recipe for organizing a DBMS.

### DBMS: Concurrency and Recovery

Two cross-cutting issues related to storage and memory management:

Relational Operators, Files and Index Management, Buffer Management, Disk Space Management are part of the Concurrency Control and Recovery. This is especially important for queries that happen at the same time or overlap or even with security.

Let's talk about the layers, and we will stop at Disk Space Management. Let's first talk about the hardware:

### Disks

- most DB systems were originally designed for magnetic "spinning" disks
    - Disk are a mechanical anachronism.
    - Instilled design ideas that applyt o using solid state disks as well

- Major implications:
    - Disk API
        - READ: transfer "page" of data from disk to RAM
        - WRITE: transfer "page" of data from RAM to disk  
        - No random reads/writes! When we read data, we have to read it sequentially. Have to read things like a tape measure.
    - Both API calls are very very slow!
        - plan carefully

    - Take CS 162 which talks more about Disk APIs

### Storage Hierarchy

1. Registers
2. L1 Cache
3. L2 Cache
4. RAM
5. SSD
6. Disk

closer to 1 is smaller and faster. Closer to 6 is bigger and slower.

Relative heirarchy will never change even with changes in tech.

Ideally, we want to currently place data in the 1 - 4, as close to the CPU as possible.

If not possible, we'll store this in SSD. Hopefully, it's something we need to keep in the SSD or Disk if no other mechanism is possible.

### Economics

$1000 at NewEgg 2022
- Mag Disk: ~40 TB for 1000 dollars
- SSD: 2.3 TB for 1000 dollars
- RAM: 128GB for 1000 dollars

We must design algos that allow us to use these things in a clever way. We can be smart with efficiency and economics.

### Components of a Disk

- Platters spin (say 15000 rpm)
- stack of DVDs (cylindrical), multiple platters. There is a spindle at the center like an axis. 
- There is an arm assembly moved in or out to position a head on a desired track
- Each one of these platters has a head, and we can move these heads such that they are moving right on top of the data that needs to be read.

An analogy:

A reading head that only has one record. And in order to play the song, we must move the reader to the track in which the song is, and then move the vinyl record.

We have different readers, and each one of these platters have a disk head or a reader, and then in order to read something from these platters, we decide to move or switch the head to move to the right position and then we read everything at the same time. 

This is why we can't do random reads. Because its gonna read whatevers under the reader at that time. So let's say we need to move to a different song. We need to move the disk head to another place and then do the reading afterwords which is costly because we need to move the physical reader from one track to another.

### Accessing a Disk page

- Time to access (read/write) a disk block:
    - seek time (moving arms to position disk head on track)
        - 2-3 ms on average
    - rotational delay (waiting for block to rotate under head)
        - 0 - 4 ms (15000 RPM)
    - transfer time (actually moving data to/from disk surface)
        - 0.25 ms per 64KB page

        - There is a lot of technology going through this. It used to be entirely metallic, now it involves more optics. Translate this into actual sound that we can hear, transferring into bytes, converting signals into 0s and 1s

- Key to lower I/O cost: reduce seek/rotational delays

- Seek time is the biggest time in the chunk, takes 2-3 ms on average, whereas others are smaller.

Each time we want to read something, we say we want to read track number x on pattern number y. We seek the reader, we move the platter, and then transfer the actual bytes.

You might think this is kinda old stuff. So let's talk about SSDs! New stuff!

### Flash (SSD)
- Organized into cells
- Actually not organized into platters and cylinders, actually organized into cells like something in a 2D array
- Each one of these rectangular things is a cell, and in the current Generation (NAND)
    - Random reads and writes, unlike the magnetic disks which does a read for all, there is no waiting for a SSD. All of these cells can be read or written simultaneously. No wait for rotational delay.

    - FIne grain reads (4-8 reads), coarse-grain writes (1-2MB) this is very expensive technology

### Flash (SSD), Pt. 2

- So read is fast and predictable
    - 4KB random reads: ~500MB/sec
- But write is not!
    - 4KB random writes: ~120 MB/sec
    - but why is this, arent cells cool and fast (concurrent)?
        - only 2k-3k erasures before failure
            - so keep moving write units around ("wear leveling")
        - Actually cells can fail and actually forget information
        - this is why typically when they say a computer has 1TB SSD it actually has more than 1TB actually, but this is because it accounts for redundancy. API-wise its similar, but operation wise very different

## Disk Space Management

### Block Level Storage
- Read and write large chunks of sequential bytes
- sequentially: next disk block is fastest because physics compared to doing random reads. (No seek time)
- Maimize usage of data per read/write
    - amortize seek delays HDDs and writes SSDs:
    if youre going all the way to PLuto, pack the spaceship full!
- Predict future behaviour
    - cache popular blcoks
    - prefetch likely to be accessed blocks
    - buffer writes to sequential blocks
    - more on these as we go
- minimize reads/writes by being clever about what we need to read and write what is necessary

### A note on terminology

> Block = unit of transfer for disk read/write 

Instead of talking about tracks, we talk about disk blocks that we are reading and writing for SSD and disks.

We'll use this unit for all storage devices

> Sometimes people also call this a page: a common synonym for "block"

We'll treat block and page as synonyms

### Back to Disk Space Management

- Lowest layer of DBMS, manages space on disk

Now lets jump back into software of disk space management

Purpose
- map pages to locations on disk
- load pages from disk to memory
- save pages back to disk and ensuring writes

Higher levels call upon this layer to:
- read/write a page
- allocate/de-allocate logical pages

### Disk Space Management: Requesting Pages

Let's talk about how we want to write software now to actually fetch a block or a page of data 

```
page = getFirstPage("Sailors");
while (!done) {
    process(page);
    page = page.nextPage();
}
```

This pseudcode reminds me of a LinkedList type structure for pages.

Physical details hidden from higher levels of system.

Higher levels may safely assume nextPage is fast
    - hence sequential runs of pages are quick to scan

Somehow get access to where sailors table lives. 

Next, let's talk about how to implement getFirstPage() and nextPage()

### Disk Space Management: Implementation

- Proposal 1: Talk to the storage device directly
    - could be very fast if you knew the device well
    - hard to program when each device has its own API
    What happens when devices change?

- Proposal 2: Run our own over filesystem (FS)
    - work with the underlying OS, so we basically assume that the OS is going to implement each of these device drivers, if you have taken CS 162, OS is responsible for talking to each of the devices and then rely on services provided by the OS to create an illusion of a giant disk that is right next to us
    - so we're not going to be interacting with the individual devices directly. 
    - we're going to be using the file system support provided by the OS instead.
    - so the problem however with this approach is that now the file system might not know what we're trying to do, it doesn't understand that we are a DBMS. we're not some random app. so therefore it doesn't understand that doing sequential reads is good or bashing writes is good for flash drives. 
    - allocate single large "contiguous" file on an empty disk
    - we need to tweak this a little bit so that we can actually do the right thing efficiently. Using local filesystem

### Using Local Filesystem

Let's talk about layering. With this abstraction, how does it actually work if we use the OS?

If we imagine we have each of these disks, magnetic or whatever, each of them is going to be controlled by the operating system, so the OS will have its own file system in the phase, and it will talk to these low level devices directly. And then for our purposes for the database, we're just going to tell the OS that we have a huge file that is stored on this entire device, please give us control of this huge file, and we will manage it itself. the goal of an OS is to manage a bunch of files that might be sitting on the same device, and then figuring out where there are conflicts maybe in names or where they reside. Now we're DBMS is in control. Illusion of an enormous file on the entire storage. We decide how to put these blocks of data. Give services to query execution engine. 

Hijacking the OS, not talk to these devices individually, build something that talks to all devices. Also don't want OS to be in our way. We want to keep track of all files ourselves. We will organize it the way we want it, just give me the whole thing. 

### Summary
OS has its own API to talk to these low level devices, and we rely on them to deal with that, but above that we assume we have access to the entire files oureselves and then we are going to organize these pages in whateer we want in order to implement the earlier picture shown for getFirstPage() and nextPage(). Implementing these two functions is the DBMS responsibility which is us but then it terms of storing everything in a big file on the disk, that's the responsibility of the OS. 

### Disk Representations:
Files, pages, records

Remember that in this class we talk about pages of data. Data includes records/row which are stored in pages. How do we organized these pages? Another abstraction layer! Design an abstraction for a page, and let's architect how to organized these pages, and then give this to Disk Management and Disk Management will use OS to reading and writing of these pages.

Let's say we had one single table. a DB file, is a collection of pages, each containing a collection of records

API for higher layers of the DBMS:
- reads: 
    - fetch a particular record by record id
        - record id is a pointer encoding pair of pageID, location on page. 
    - scan all records
        - possibly with some conditions on the records to be retrieved but this is for a select * query.
- updates:
    - insert/delete/modify record

### Many DB File Structures

Information is stored in files in multiple ways

- Unordered Heap Files
    - Records placed arbitrarily across pages, unordered

- Clustered Heap files, sorted by id or a column

- Sorted Files, pages and records are in strict sorted order

- Index Files, B+ trees, linear hashing, may contain records or point to records in other files. 

- Focus on unordered Heap Files for now, we'll see other soon.

### Unordered Heap Files

- Collection of records in no particular order

The records are not sorted in anyways, heaps are not to be confused with the data-structure for efficient max/min lookup.

As file shrinks/grows, pages (de)allocated

To support record level operations, we must
    - keep track of the pages in a file
    - keep track of free space on pages
    - keep track of the records on a page

### Take 1: Heap File as List

- Heap file has one special Header page
    - Location of the heap file and the header page saved in catalog

Header page reminds me of a sentinel node that connects to two DLLists. One DLList contains all Full pages. The other contains the pages with Free Space. Both LinkedLists contain Data Pages.

But why is there a seperation between free pages and pages that are full? We are a DBMS, and we have a lot of updates, it's not static data, the data is frequently going to change! Having quick access to the free space is benficial, we don't have to scan page after page to realize that there is no space left. 

Each page contains 2 pointers: pls free space and data

What is wrong with this?
- Find a page with enough space for a 20 byte record?
- Might need to access many pages w / free space to check

### Take 2: Use a Page Directory

- why not have 2 linked lists. we can have a directory with multiple header pages each encoding:
    - Header page with cells that point to Data Pages, and each header page has a next pointer that points to a different header page.
    - also gonna store the number of free bytes on the page

- There can be multiple such header pages. Headers are DataPage[]

- Directory, with multiple Header Pages, each encoding:
    - a pointer to page
    - number of free bytes on the page

Advantages:
- better lookup for space to store
- might be able to keep directory in cache, directory does not occupy a lot of pages

Might be able to keep this in the cache which means there will be efficiency with the caching.

Each of the header pages stores how much space is left.

We can optimize the page directory further:
    - compressing header page, keeping header page in sorted order based on free space, etc.
    - But diminishing returns

diminishing returns to compress directories into directories, every time we reda we uncompress, space is gonna be awesome, but time is the consequence of the space.

### Summary
- Table encoded as files which are collections of pages
- Page directory provides locations of pages and free space

### A note on imagery

Data in memory or disk is stored in linear order

On the disk, things are stored in a sequential file. Each boxin an array is a record, we imagine we rap it and that its in row order form.

### Page basics: The Header

Header may contain metadata about the page
- Number of records
- Free Space
- Maybe a next/last pointer to other pages
- Bitmaps, slot tables
- etc.

### Things to address

Some options
- Record length? Fixed or Variable
- Page layout? Packed or Unpacked

Some questions:
- Find records by record id
    - record id = (Page, location in page)

- How do we add and delete records?

### Fixed Length Records, Packed
- Pack records densely

We have a Page Header which does housekeeping and free space, and then after that a single record, and then another record, and then anther record like row order form. 

Record id corresponds to pageId, record number in the page. I guess the page is like an array in this case. 

Arithmetic to figure out where we read off, I think this is like pointer arithmetic

adding a record is just appending. 

Deleting is a very costly operations because we have to fetch the record after that and then figure out how to consolidate the rest of the space. We need to move everything to the right of the record which is a linear cost operation shifting everything by 1. removing record 0 is painful!

### Fixed Length Records: Unpacked

Someone actually thought about this and introduced a bitmap instead. If we instead store these record numbers we should have a bitmap. The bitmap denotes slots with records. Bitmap introduces the fact that we can have gaps in our records, meaning we don't have to perform shifts. In the page header, we will have a bitmap that stores what is actually occupied and what is not occupied.

Remember we are still assuming that every record is 20 bytes. So if we know the page size and we also know the record size, then we can pregenerate this bitmap which stores which of the slots are actually taken, basically a boolean!

In order to retrieve a record, we just ask it to say, I want pageId this and slotId that.

Insert: find first empty slot in bitmap and then insert

Delete is also easy, no more shifting, just clear

so whats the tradeoff? its not so much the contiguous space, its actually the fact that we require fixed record bytes. If we have gaps we are not doing work by reading that gap, if we do a sequential read, we will be able to fetch all the records ideally. If the page has a lot of gaps, we might not able to read a lot of it. This might result in grabbing more pages when the goal is to reduce the number of pages.

### Variable Length Records

- We've already seen that packed isnt the best idea, so lets consider the unpacked case

- Didn't we say relations have the same schema. Variables means the number of bytes.

- what if we are storing a string which has more characters than other characters. If we declare the string column to be 20 characters than that is fixed size but what if this is a waste. Why don't we save variable length.

> Datatype varchar means variable characters, variable size

DBMS has the option of not storing all the fixed length explicitly. 

### First relocate metadata to footer.

we'll see why soon

### Slotted page
- footer will have slot directory, this directory has record ids and pointers to them, we have to store the pointers explicitly, cuz offset will be different for each record and this needs to be saved in the page. Page 2 is the page, and record 4 will be a pointer. 

- length + pointer to beginning if record
    - slots are filled starting from the end.

Deleting looks tricky, but it is very similar to bitmap. Pointers instead of booleans. Remove the record from slot directory, do not need organize everything else, because we are talking about unpacked version. 

Insertion just needs to worry about space.


