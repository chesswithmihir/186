# Introduction to DBMS Internals

We will be looking at DBMS Architecture and Data Storage today.

So let's do a little bit of recap:

Here is a course overview:

- Unit 1: Relational model and SQL
- Unit 2: Storage and indexing
- Unit 3: Query execution
- Unit 4: Query Optimization
- Unit 5: Conceptual design
- Unit 6: Transactions
- Unit 7: Recovery
- Unit 8: NoSQL

We are currentlyon Unit 2 and we are done with Unit 1 to get your hands dirty with SQL. Now we are doing a deep dive into how to actually build a DBMS.

The first topic is to go all the way down in the software stack to talk about how data is organized in disks. For those of you who enjoyed 61C, you will enjoy the class a lot. If not, you have Professor Cheung's condolences. 

### DBMS Architecture

We typically talk about cients and this is for anyone who wants to write queries. 

At the very bottom of the stack is actually the File System. This is where all the data is stored or where the data actually is. Fundamentally, we want to store the data in the file system.

How is the query then executed?

The query first gets parsed, then checked and then verified by the SQL in the sense that its referring to the right tables and that the tables actually exist. We actually refer to columns that are there. This is the verification. Then there is some optimization to perform the actual query.

Then from SQL queries, we make a SQL query execution plan which has the goal of how to retrieve the data from the files. No longer a String of SQL. Now it's a Tree.

| Node | parent |
| -- | -- |
|Heap Scan Reserves | Indexed Join | 
| Indexed Scan Sailors | Indexed Join | 
|Indexed Join | GroupBy (Age) |

Executing the plan goes into details about which files we go into. Do we have indices? There is an index management component that keeps track of which files to receive. Even another layer is buffer management, if we have access to the same data over and over again, we might wanna keep this in memory. In 61C, we learned about cache. We must control cache, and this is where buffer management is. I think this is like the TLB.

Finally, we have the disk management component, which opens the file from the disk and then retrieves the data.

So this is the rough division of labor.

If you don't understand every single detail, thats what the next 2 months are for lol.

Architecture of a DBMS
- Organized in layers

Useful to take in future classes. OS has different abstractions but same principles of levels and abstractions. Very good for systems classes.

Example of good systems design. If you open a commercial DB implementation or any open source DB, they all have this division of labor to show that all have the same abstractions. A lot of the startups do the same thing. Cookbook recipe for organizing a DBMS.

### DBMS: Concurrency and Recovery

Two cross-cutting issues related to storage and memory management:

Relational Operators, Files and Index Management, Buffer Management, Disk Space Management are part of the Concurrency Control and Recovery. This is especially important for queries that happen at the same time or overlap or even with security.

Let's talk about the layers, and we will stop at Disk Space Management. Let's first talk about the hardware:

### Disks

- most DB systems were originally designed for magnetic "spinning" disks
    - Disk are a mechanical anachronism.
    - Instilled design ideas that applyt o using solid state disks as well

- Major implications:
    - Disk API
        - READ: transfer "page" of data from disk to RAM
        - WRITE: transfer "page" of data from RAM to disk  
        - No random reads/writes! When we read data, we have to read it sequentially. Have to read things like a tape measure.
    - Both API calls are very very slow!
        - plan carefully

    - Take CS 162 which talks more about Disk APIs

### Storage Hierarchy

1. Registers
2. L1 Cache
3. L2 Cache
4. RAM
5. SSD
6. Disk

closer to 1 is smaller and faster. Closer to 6 is bigger and slower.

Relative heirarchy will never change even with changes in tech.

Ideally, we want to currently place data in the 1 - 4, as close to the CPU as possible.

If not possible, we'll store this in SSD. Hopefully, it's something we need to keep in the SSD or Disk if no other mechanism is possible.

### Economics

$1000 at NewEgg 2022
- Mag Disk: ~40 TB for 1000 dollars
- SSD: 2.3 TB for 1000 dollars
- RAM: 128GB for 1000 dollars

We must design algos that allow us to use these things in a clever way. We can be smart with efficiency and economics.

### Components of a Disk

- Platters spin (say 15000 rpm)
- stack of DVDs (cylindrical), multiple platters. There is a spindle at the center like an axis. 
- There is an arm assembly moved in or out to position a head on a desired track
- Each one of these platters has a head, and we can move these heads such that they are moving right on top of the data that needs to be read.

An analogy:

A reading head that only has one record. And in order to play the song, we must move the reader to the track in which the song is, and then move the vinyl record.

We have different readers, and each one of these platters have a disk head or a reader, and then in order to read something from these platters, we decide to move or switch the head to move to the right position and then we read everything at the same time. 

This is why we can't do random reads. Because its gonna read whatevers under the reader at that time. So let's say we need to move to a different song. We need to move the disk head to another place and then do the reading afterwords which is costly because we need to move the physical reader from one track to another.

### Accessing a Disk page

- Time to access (read/write) a disk block:
    - seek time (moving arms to position disk head on track)
        - 2-3 ms on average
    - rotational delay (waiting for block to rotate under head)
        - 0 - 4 ms (15000 RPM)
    - transfer time (actually moving data to/from disk surface)
        - 0.25 ms per 64KB page

        - There is a lot of technology going through this. It used to be entirely metallic, now it involves more optics. Translate this into actual sound that we can hear, transferring into bytes, converting signals into 0s and 1s

- Key to lower I/O cost: reduce seek/rotational delays

- Seek time is the biggest time in the chunk, takes 2-3 ms on average, whereas others are smaller.

Each time we want to read something, we say we want to read track number x on pattern number y. We seek the reader, we move the platter, and then transfer the actual bytes.

You might think this is kinda old stuff. So let's talk about SSDs! New stuff!

### Flash (SSD)
- Organized into cells
- Actually not organized into platters and cylinders, actually organized into cells like something in a 2D array
- Each one of these rectangular things is a cell, and in the current Generation (NAND)
    - Random reads and writes, unlike the magnetic disks which does a read for all, there is no waiting for a SSD. All of these cells can be read or written simultaneously. No wait for rotational delay.

    - FIne grain reads (4-8 reads), coarse-grain writes (1-2MB) this is very expensive technology

### Flash (SSD), Pt. 2

- So read is fast and predictable
    - 4KB random reads: ~500MB/sec
- But write is not!
    - 4KB random writes: ~120 MB/sec
    - but why is this, arent cells cool and fast (concurrent)?
        - only 2k-3k erasures before failure
            - so keep moving write units around ("wear leveling")
        - Actually cells can fail and actually forget information
        - this is why typically when they say a computer has 1TB SSD it actually has more than 1TB actually, but this is because it accounts for redundancy. API-wise its similar, but operation wise very different

## Disk Space Management

### Block Level Storage
- Read and write large chunks of sequential bytes
- sequentially: next disk block is fastest because physics compared to doing random reads. (No seek time)
- Maimize usage of data per read/write
    - amortize seek delays HDDs and writes SSDs:
    if youre going all the way to PLuto, pack the spaceship full!
- Predict future behaviour
    - cache popular blcoks
    - prefetch likely to be accessed blocks
    - buffer writes to sequential blocks
    - more on these as we go
- minimize reads/writes by being clever about what we need to read and write what is necessary

### A note on terminology

> Block = unit of transfer for disk read/write 

Instead of talking about tracks, we talk about disk blocks that we are reading and writing for SSD and disks.

We'll use this unit for all storage devices

> Sometimes people also call this a page: a common synonym for "block"

We'll treat block and page as synonyms

### Back to Disk Space Management

- Lowest layer of DBMS, manages space on disk

Now lets jump back into software of disk space management

Purpose
- map pages to locations on disk
- load pages from disk to memory
- save pages back to disk and ensuring writes

Higher levels call upon this layer to:
- read/write a page
- allocate/de-allocate logical pages

### Disk Space Management: Requesting Pages

Let's talk about how we want to write software now to actually fetch a block or a page of data 

```
page = getFirstPage("Sailors");
while (!done) {
    process(page);
    page = page.nextPage();
}
```

This pseudcode reminds me of a LinkedList type structure for pages.

Physical details hidden from higher levels of system.

Higher levels may safely assume nextPage is fast
    - hence sequential runs of pages are quick to scan

Somehow get access to where sailors table lives. 

Next, let's talk about how to implement getFirstPage() and nextPage()

### Disk Space Management: Implementation

- Proposal 1: Talk to the storage device directly
    - could be very fast if you knew the device well
    - hard to program when each device has its own API
    What happens when devices change?

- Proposal 2: Run our own over filesystem (FS)
    - work with the underlying OS, so we basically assume that the OS is going to implement each of these device drivers, if you have taken CS 162, OS is responsible for talking to each of the devices and then rely on services provided by the OS to create an illusion of a giant disk that is right next to us
    - so we're not going to be interacting with the individual devices directly. 
    - we're going to be using the file system support provided by the OS instead.
    - so the problem however with this approach is that now the file system might not know what we're trying to do, it doesn't understand that we are a DBMS. we're not some random app. so therefore it doesn't understand that doing sequential reads is good or bashing writes is good for flash drives. 
    - allocate single large "contiguous" file on an empty disk
    - we need to tweak this a little bit so that we can actually do the right thing efficiently. Using local filesystem

### Using Local Filesystem

Let's talk about layering. With this abstraction, how does it actually work if we use the OS?

If we imagine we have each of these disks, magnetic or whatever, each of them is going to be controlled by the operating system, so the OS will have its own file system in the phase, and it will talk to these low level devices directly. And then for our purposes for the database, we're just going to tell the OS that we have a huge file that is stored on this entire device, please give us control of this huge file, and we will manage it itself. the goal of an OS is to manage a bunch of files that might be sitting on the same device, and then figuring out where there are conflicts maybe in names or where they reside. Now we're DBMS is in control. Illusion of an enormous file on the entire storage. We decide how to put these blocks of data. Give services to query execution engine. 

Hijacking the OS, not talk to these devices individually, build something that talks to all devices. Also don't want OS to be in our way. We want to keep track of all files ourselves. We will organize it the way we want it, just give me the whole thing. 

### Summary
OS has its own API to talk to these low level devices, and we rely on them to deal with that, but above that we assume we have access to the entire files oureselves and then we are going to organize these pages in whateer we want in order to implement the earlier picture shown for getFirstPage() and nextPage(). Implementing these two functions is the DBMS responsibility which is us but then it terms of storing everything in a big file on the disk, that's the responsibility of the OS. 

write more notes at 00:48 lecture 3