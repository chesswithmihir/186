# Buffer Manager

## Introduction

So far, we have discussed how disk space is managed at the lowest level of the database management system and how files and indexes are managed in our page-based database system. We will now explore the interface between these two levels on teh DBMS - the buffer.

Database Stack: <br>

1. SQL Client - **Completed**
2. Query Parsing & Optimization
3. Relational Operators
4. Files and Index Management - **Completed**
5. Buffer Management - **You Are Here**
6. Disk Space Management - **Completed**

> Buffer Manger: The buffer manager is responsible for managing pages in memory and processing page requests from the file and index manager. Remember, space on memory is limited, so we cannot afford to store all pages in the buffer pool. The buffer manager is responisbile for the eviction policy, or choosing which pages to evict when space is filled up. When pages are evicted from memory or new pages are read in to memory, the buffer manager communicates with the disk space manager to perform the required disk operations.

## 2 Buffer Pool

Memory is converted into a buffer pool by partitioning the space into frames that pages can be placed in. A buffer frame can hold the same amount of data as a page can (so a page fits perfectly into a frame). To efficiently track frames, the buffer manager allocates additional space in memory for a metadata table.

| Frame ID | Page ID | Dirty Bit | Pin Count |
| -- | -- | -- | -- |
| 0 | 5 | 1 | 3 |
| 1 | 3 | 0 | 1 |
| 2 | 10 | 1 | 0 |
| 3 | | | |

The table tracks 4 pieces of information

1) **Frame ID** that is uniquely associated with a memory address
2) **Page ID** for determining which page a frame currently contains
3) **Dirty Bit** for verifying whether or not a page has been modified
4) **Pin Count**

## 3 Handling Page Requests

When pages are requested from the buffer manager and the page already exists within memory, the page's pin count is incrememented and the page's memory address is returned.

If the page does not exist in the buffer pool and there is still space, the next empty frame is found and the page is read into that frame. The page's pin count is set to 1 and the page's memory address is returned. 

In the case where the page does not exist and there are no empty frames left, a replacement policy must be used to determine which page to evict.

The choice of replacement policy is heavily dependent on page access patterns and the optimal policy is chosen by counting page hits. A **page hit** is when a requested page can be found in memory without having to go to disk. Each **page miss** incurs an additional IO cost, so a good eviction policy is critical for performance. The **hit rate** for an access pattern is defined as # of page hits / (# of page hits + # of page misses) or simply, # page of hits / # of page accesses.

Additionally, if the evicted page has the dirty bit set, the page is written to disk to ensure that updates are persisted. The dirty bit is set to 1 if and when a page is written to with updates in memory. The dirty bit is set to 0 once the page is written back to disk.

Once the requestor completes its workload, it is responsible for telling the buffer manager to decrement the pin count associated with pages that it previouly used.

## 4 LRU Replacement and Clock Policy

A commonly used replacement policy is LRU (Least Recently Used). When new pages need to be read into a full buffer pool, the least recently used unpinned page which has pin count = 0 and the lowest value in the Last Used column is evicted. To track page usage, a last used column is added to the metadata table and measures the latest time at which a page's pin count is decremented.

So when a pin is 0 meaning that no requestors are currently using that page and also we used the lowest numnber in the last used column because this will be kk

| Frame ID | Page ID | Dirty Bit | Pin Count | Last Used |
| -- | -- | -- | -- | -- |
| 0 | 5 | 1 | 3 | 20 |
| 1 | 3 | 0 | 1 | 32 |
| 2 | 10 | 1 | 0 | 40 | 
| 3 | 6 | 0 | 0 | 25 | 
| 4 | 1 | 0 | 1 | 15 |

As we can see here there are only two Page IDs that currently have 0 pin count and also the lowest Last Used out of 25 and 40 is the one with 25. So the row with Page ID = 6 is the one that would be evicted. 

Now notice that implementing LRU is quite costly. This is why we introduct the Clock policy which provides an alternative implementation that efficiently approximates LRU using a ref bit (recently referenced) column in the metadata table and a clock hand variable to track the current frame in consideration. Using a ref bit reduces the cost of both space and time. Only a single bit per frame is needed instead of multiple bits to store a Last Used value. With respect to time, the buffer manager just follows the clock hand. In LRU, the buffer manager has to spend time searching for the minimum value in the Last Used column.

| Frame ID | Page ID | Dirty Bit | Pin Count | Ref Bit |
| -- | -- | -- | -- | -- |
| 0 | 5 | 1 | 3 | 1 |
| 1 | 3 | 0 | 1 | 1 |
| 2 | 10 | 1 | 0 | 1 |
| 3 | 6 | 0 | 0 | 1 |
| 4 | 1 | 0 | 1 | 0 |

**Clock Hand** : 2

The Clock policy algorithm treats the metadata table as a circular list of frames. It sets the clock hand to the first unpinned frame upon start and sets the ref bit on each page's corresponding row to 1 when it is initially read into a frame. The policy works as follows when trying to evict:

- Iterate through frames within the table, skipping pinned pages and wrapping around to frame 0 upon reaching the end, until the first unpinned frame with ref bit = 0 is found.

- During each iteration, if the current frame's ref bit = 1, set the ref bit to 0 and move the clock hand to the next frame.

- Upon reaching a frame with ref bit = 0, evict the existing page (and write it to disk if the dirty bit is set; then set the dirty bit to 0), read in the new page, set the frame's ref bit to 1, and move the clock hand to the next frame

If accessing a page currently in the buffer pool, the clock policy sets the page's ref bit to 1 **without moving the clock hand**.

## 4.1 Sequential Scannin Performance - LRU

LRU performs well overall but performance suffers when a set of pages S, where |*S*| > buffer pool size, are accessed multiple times repeatedly.

To highlight this point, consider a 3 frame buffer pool using LRU and having the access pattern: 

A B C D repeatedly. Each time a new letter is called the old one is kicked out and the old one is important for the next iteration! 0 cache hits is a big no-no for a strong cache policy!

## MRU Replacement

Another commonly used replacement policy is MRU (Most Recently Used). Instead of evicting the least recently used unpinned page, evict the most recently used unpinned page measured by when the page's pin count was last decremented. This has the belief that we just saw something we're not going to use it 
